{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 56146,
     "status": "ok",
     "timestamp": 1573639383668,
     "user": {
      "displayName": "Gero Lapan",
      "photoUrl": "",
      "userId": "12575555955150639304"
     },
     "user_tz": -60
    },
    "id": "XNigl-_y7C_F",
    "outputId": "3f72758b-1340-4906-debe-bf205ccf7a54"
   },
   "outputs": [],
   "source": [
    "IS_LINUX = False\n",
    "from sys import platform\n",
    "if platform == \"linux\" or platform == \"linux2\":\n",
    "  IS_LINUX = True\n",
    "if IS_LINUX:\n",
    "    !pip install tensorflow-gpu\n",
    "    !pip install jsonpickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 135048,
     "status": "ok",
     "timestamp": 1573639462577,
     "user": {
      "displayName": "Gero Lapan",
      "photoUrl": "",
      "userId": "12575555955150639304"
     },
     "user_tz": -60
    },
    "id": "DswxGqi-sw4E",
    "outputId": "95df0a77-6f92-48e8-cb9f-9338fc037cbe"
   },
   "outputs": [],
   "source": [
    "if IS_LINUX:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 141690,
     "status": "ok",
     "timestamp": 1573639470719,
     "user": {
      "displayName": "Gero Lapan",
      "photoUrl": "",
      "userId": "12575555955150639304"
     },
     "user_tz": -60
    },
    "id": "iUj0zEbRs1ts",
    "outputId": "a205ffcd-6a0d-4a5a-c977-1bba2bcccaab"
   },
   "outputs": [],
   "source": [
    "if IS_LINUX:\n",
    "    %cd /content/drive/My\\ Drive/MastersThesis\n",
    "    !ls\n",
    "    !pwd\n",
    "    import sys\n",
    "    sys.path.append('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 143300,
     "status": "ok",
     "timestamp": 1573639474561,
     "user": {
      "displayName": "Gero Lapan",
      "photoUrl": "",
      "userId": "12575555955150639304"
     },
     "user_tz": -60
    },
    "id": "CAPxLTTaeaaS",
    "outputId": "6c6e2342-c480-498f-80f3-4b14d3a4b643"
   },
   "outputs": [],
   "source": [
    "import global_functions\n",
    "global_functions.on_start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 141998,
     "status": "ok",
     "timestamp": 1573639474561,
     "user": {
      "displayName": "Gero Lapan",
      "photoUrl": "",
      "userId": "12575555955150639304"
     },
     "user_tz": -60
    },
    "id": "DTKNraAlGLLO",
    "outputId": "c1164863-8f93-47c8-f6ef-191e7fabe3a3"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "#2.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XD_m4k8AtuU_",
    "outputId": "38c5d0d0-9677-4299-a159-e2f1636033f3"
   },
   "outputs": [],
   "source": [
    "import experiments, datasets, training_data\n",
    "import models\n",
    "import constants\n",
    "import vizualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a8dtVAkVBT8c"
   },
   "outputs": [],
   "source": [
    "#basic_model = models.BasicModelProvider()(datasets.FashionMnistDataset())\n",
    "trained_models.autoencoder.set_autoencoder_trainable(False)\n",
    "existing_model =  models.ExistingModelProvider(lambda: trained_models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = experiments.ExperimentAutoencoder(datasets.MnistDataset, models.BasicModelProvider(),\n",
    "                                                    training_data.BasicTrainingDataGeneratorAutoencoder())\n",
    "result = exp.train(training_data.BasicTrainParametersAutoencoder(100, 128, 20, True, 1.0, 1e-5,\n",
    "                                                                             None,\n",
    "                                                                             False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "exp = experiments.ExperimentClassifier(datasets.FashionMnistDataset, existing_model,\n",
    "                                                   training_data.BasicTrainingDataGeneratorClassifier())\n",
    "result = exp.train(training_data.BasicTrainParametersClassifier(100, 128, 20, True, 1.0, 1e-6, True,\n",
    "                                                                            None,\n",
    "                                                                            False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 141904,
     "status": "ok",
     "timestamp": 1573639478075,
     "user": {
      "displayName": "Gero Lapan",
      "photoUrl": "",
      "userId": "12575555955150639304"
     },
     "user_tz": -60
    },
    "id": "RPXVrTrtuM5S",
    "outputId": "68190bbe-973f-401e-dfa6-f4c4169cc5ab"
   },
   "outputs": [],
   "source": [
    "import vizualizer, experiments , constants, importlib, datasets, models, predictors, training_data\n",
    "importlib.reload(experiments)\n",
    "importlib.reload(vizualizer)\n",
    "importlib.reload(models)\n",
    "importlib.reload(constants)\n",
    "importlib.reload(predictors)\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "results = experiments.ExperimentBase.load_experiment_results(constants.ExperimentsPaths.FashionMnist.CLASSIFIER, True)\n",
    "experiment = results[-1].experiment\n",
    "trained_models_classifier = experiment.model_provider()\n",
    "results = experiments.ExperimentBase.load_experiment_results(constants.ExperimentsPaths.FashionMnist.AUTOENCODER, True)\n",
    "experiment = results[-1].experiment\n",
    "trained_models_autoencoder = experiment.model_provider()\n",
    "\n",
    "#print(len(results))    \n",
    "#vizualizer.Vizualizer.vizualize([result.train_history for result in results], 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3Trz-pItxZ3a"
   },
   "outputs": [],
   "source": [
    "fashion_mnist = datasets.FashionMnistDataset()\n",
    "predictions_autoencoder = experiments.ExperimentAutoencoder.predict_test(fashion_mnist ,trained_models)\n",
    "experiments.ExperimentAutoencoder.evaluate_on_test(fashion_mnist, trained_models)\n",
    "vizualizer.Vizualizer.show_random_autoencoder_images(fashion_mnist, fashion_mnist.get_test_images(), predictions_autoencoder, 5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trained_models = experiment.model_provider()\n",
    "metrics = [ constants.Metrics.VAL_CLASSIFIER_OUT_ACCURACY, constants.Metrics.VAL_AUTOENCODER_OUT_LOSS]\n",
    "params = vizualizer.VizualizeParams(0, 100, 5,False, False, metrics)\n",
    "#vizualizer.Vizualizer.vizualize([result.train_history for result in results], params)\n",
    "vizualizer.Vizualizer.vizualize([result.train_history for result in results[:]], params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 159184,
     "status": "ok",
     "timestamp": 1573639499965,
     "user": {
      "displayName": "Gero Lapan",
      "photoUrl": "",
      "userId": "12575555955150639304"
     },
     "user_tz": -60
    },
    "id": "NTSmy_R-Evtz",
    "outputId": "f07b90cb-662b-4fdd-a38b-3ebe87b73933"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/1 - 1s\n",
      "Correct: 9387\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "fashion_mnist = datasets.FashionMnistDataset()\n",
    "predictions_classifier = experiments.ExperimentClassifier.predict_test(fashion_mnist, trained_models_classifier)\n",
    "predictions_classifier = np.argmax(predictions_classifier, axis = 1)\n",
    "test_images = fashion_mnist.get_test_images()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 158029,
     "status": "ok",
     "timestamp": 1573639500386,
     "user": {
      "displayName": "Gero Lapan",
      "photoUrl": "",
      "userId": "12575555955150639304"
     },
     "user_tz": -60
    },
    "id": "AKA3nrsZGQXi",
    "outputId": "6a514f1f-0789-495e-de3a-046022a70936"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "613"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_classifier = [i for i, value in enumerate(fashion_mnist.get_test_labels()) if predictions_classifier[i] != value]\n",
    "correct_classifier = [i for i, value in enumerate(fashion_mnist.get_test_labels()) if predictions_classifier[i] == value]\n",
    "len(incorrect_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1219,
     "status": "ok",
     "timestamp": 1573639723907,
     "user": {
      "displayName": "Gero Lapan",
      "photoUrl": "",
      "userId": "12575555955150639304"
     },
     "user_tz": -60
    },
    "id": "LlgTctQhONLn",
    "outputId": "afdb57ea-523b-4931-8d3a-d2152aa21e67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9387/1 - 2s - loss: 0.2250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.24337510873178736"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test_images[incorrect_classifier]\n",
    "#trained_models_autoencoder.autoencoder.evaluate(test_images[incorrect_classifier],test_images[incorrect_classifier], verbose=2)\n",
    "trained_models_autoencoder.autoencoder.evaluate(test_images[correct_classifier],test_images[correct_classifier], verbose=2)\n",
    "#trained_models_autoencoder.autoencoder.evaluate(test_images,test_images, verbose=2)\n",
    "#incorrect_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kwfo9KMgEvt1",
    "outputId": "d0444333-3836-4fbf-e978-c75832989410"
   },
   "outputs": [],
   "source": [
    "vizualizer.Vizualizer.show_autoencoder_images(datasets.FashionMnistDataset(), test_images, predictions_autoencoder, 5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fev4H-4ZEvt3"
   },
   "outputs": [],
   "source": [
    "#ev = experiments.ExperimentAutoencoder.evaluate_on_train(datasets.MnistDataset() ,trained_models)\n",
    "zoznam__fashion_mnist = []\n",
    "test_images :datasets.Dataset = datasets.FashionMnistDataset().get_train_images()\n",
    "for image in test_images:\n",
    "    image = image.reshape(1, 28, 28, 1)\n",
    "    evaluation = trained_models.autoencoder.evaluate(image, image, verbose = 0)\n",
    "    zoznam__fashion_mnist.append(evaluation)\n",
    "import numpy as np    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z0c8GHYWEvt5"
   },
   "outputs": [],
   "source": [
    "np.mean(zoznam__fashion_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1230,
     "status": "ok",
     "timestamp": 1573035712111,
     "user": {
      "displayName": "Gero Lapan",
      "photoUrl": "",
      "userId": "12575555955150639304"
     },
     "user_tz": -60
    },
    "id": "3bFJfNAkiLUr",
    "outputId": "0d9c21aa-9a08-4c53-f02b-49338d813c26"
   },
   "outputs": [],
   "source": [
    "last_layer = trained_models.classifier.layers[-1]\n",
    "print(last_layer.activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S0Sza95piLU1"
   },
   "outputs": [],
   "source": [
    "trained_models.make_classifier_without_activation()\n",
    "#trained_models.make_classifier_with_sigmoid_activation()\n",
    "#spomenut ho, ze bol - histogram sposobil, ze hodnoty boli viac na sebe a pre opacne datasety su podobne, neoddeli mi data. \n",
    "#trained_models.make_classifier_with_softmax_activation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xbr2cLF-jExd"
   },
   "outputs": [],
   "source": [
    "predictors.Predictor.predict_for_subclasses(datasets.MnistDataset(),  datasets.FashionMnistDataset(), trained_models, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 499
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13155,
     "status": "ok",
     "timestamp": 1573035881910,
     "user": {
      "displayName": "Gero Lapan",
      "photoUrl": "",
      "userId": "12575555955150639304"
     },
     "user_tz": -60
    },
    "id": "G7HjbtF1j24b",
    "outputId": "639d9dde-1679-4da2-8780-c3ee9abec99b"
   },
   "outputs": [],
   "source": [
    "my_classes, distance = predictors.SquereDistanceFromMean().predict_test_based_on_train_treshoald( datasets.MnistDataset(), trained_models, 10.0)\n",
    "#my_classes, distance = predictors.SquereDistanceFromMean().predict_train( datasets.FashionMnistDataset(), trained_models, None)\n",
    "vizualizer.Vizualizer.plot_bins(distance, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1634,
     "status": "ok",
     "timestamp": 1573035773708,
     "user": {
      "displayName": "Gero Lapan",
      "photoUrl": "",
      "userId": "12575555955150639304"
     },
     "user_tz": -60
    },
    "id": "7yma3mlRiLU3",
    "outputId": "0eb8fabe-72bd-424a-be2d-482d892e2eff"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.percentile(distance, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-pDEp0ihlrln"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F-_VGv-niLVY"
   },
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class Predictor(ABC):\n",
    "    def predict_train(self, dataset, model, threashold = None):\n",
    "        return self.predict(dataset.get_train_images(), dataset.get_train_labels(), model, threashold)\n",
    "        \n",
    "    def predict_test(self, dataset, model, threashold = None):\n",
    "        return self.predict(dataset.get_test_images(), dataset.get_test_labels(), model, threashold)\n",
    "        \n",
    "    def predict_test_based_on_train_treshoald(self, dataset, model, percentile):\n",
    "        _, distance_train = self.predict_train(dataset, model)\n",
    "        threashold_for_test =  np.percentile(distance_train, percentile)\n",
    "        return self.predict_test(dataset, model, threashold_for_test), threashold_for_test\n",
    "    \n",
    "    @abstractmethod\n",
    "    def predict(self, images, labels , model, threashold):\n",
    "        pass\n",
    "    \n",
    "\n",
    "class AbsDistanceFromPredicted(Predictor):    \n",
    "    \n",
    "    def predict(self, images, labels , model, threashold):\n",
    "        predictions = model.classifier.predict(images)\n",
    "        my_classes = predictions.argmax(axis = 1)\n",
    "        distances = np.zeros_like(my_classes)\n",
    "        for index, _ in enumerate(predictions):\n",
    "            classes_values = predictions[index]\n",
    "            my_predicted_class = my_classes[index]\n",
    "            distance = 0.0\n",
    "            for index_class_value, class_value in enumerate(classes_values):\n",
    "                if index_class_value == my_predicted_class:\n",
    "                    continue\n",
    "                distance += abs(classes_values[my_predicted_class] - class_value)\n",
    "            if threashold is not None and distance < threashold:\n",
    "                my_classes[index] = -1\n",
    "            distances[index] = distance\n",
    "        print(\"correct: \", (labels == my_classes).sum() ) \n",
    "        print(\"unknown: \", (-1 == my_classes).sum() )\n",
    "        return my_classes, distances\n",
    "\n",
    "\n",
    "    \n",
    "class SquereDistanceFromPredicted(Predictor):\n",
    "    \n",
    "    def predict(self, images, labels , model, threashold):\n",
    "        predictions = model.classifier.predict(images)\n",
    "        my_classes = predictions.argmax(axis = 1)\n",
    "        distances = np.zeros_like(my_classes)\n",
    "        for index, _ in enumerate(predictions):\n",
    "            classes_values = predictions[index]\n",
    "            my_predicted_class = my_classes[index]\n",
    "            distance = 0.0\n",
    "            for index_class_value, class_value in enumerate(classes_values):\n",
    "                if index_class_value == my_predicted_class:\n",
    "                    continue\n",
    "            \n",
    "                distance += np.square(classes_values[my_predicted_class] - class_value)\n",
    "            #distance /= (len(classes_values) - 1)\n",
    "            if threashold is not None and distance < threashold:\n",
    "                my_classes[index] = -1\n",
    "            distances[index] = distance\n",
    "        print(\"correct: \", (labels == my_classes).sum() ) \n",
    "        print(\"unknown: \", (-1 == my_classes).sum() )\n",
    "        return my_classes, distances\n",
    "    \n",
    "class SumAbs(Predictor):\n",
    "\n",
    "    def predict(self, images, labels , model, threashold):\n",
    "        predictions = model.classifier.predict(images)\n",
    "        my_classes = predictions.argmax(axis = 1)\n",
    "        sums = np.zeros_like(my_classes)\n",
    "        for index, _ in enumerate(predictions):        \n",
    "            classes_values = predictions[index]\n",
    "            sum_values = np.sum(np.absolute(classes_values)) \n",
    "            if threashold is not None and sum_values < threashold:\n",
    "                my_classes[index] = -1\n",
    "            sums[index] = sum_values\n",
    "        print(\"correct: \", (labels == my_classes).sum() ) \n",
    "        print(\"unknown: \", (-1 == my_classes).sum() )\n",
    "        return my_classes, sums\n",
    "\n",
    "class SumSquere(Predictor):    \n",
    "    \n",
    "    def predict(self, images, labels , model, threashold):\n",
    "        predictions = model.classifier.predict(images)\n",
    "        my_classes = predictions.argmax(axis = 1)\n",
    "        sums = np.zeros_like(my_classes)\n",
    "        for index, _ in enumerate(predictions):        \n",
    "            classes_values = predictions[index]\n",
    "            sum_values = np.sum(np.square(classes_values)) \n",
    "            if threashold is not None and sum_values < threashold:\n",
    "                my_classes[index] = -1\n",
    "            sums[index] = sum_values\n",
    "        print(\"correct: \", (labels == my_classes).sum() ) \n",
    "        print(\"unknown: \", (-1 == my_classes).sum() )\n",
    "        return my_classes, sums\n",
    "\n",
    "\n",
    "# na zaklade hodnoty maximalnej predikovanej hodnoty a thresholdu, ziadna suma ani vzdialenost\n",
    "# 13.26\n",
    "class MaxArgPredictor(Predictor):\n",
    "\n",
    "    def predict(self, images, labels , model, threashold):\n",
    "        predictions = model.classifier.predict(images)\n",
    "        my_classes = predictions.argmax(axis = 1)\n",
    "        sums = np.zeros_like(my_classes)\n",
    "        for index, _ in enumerate(predictions):        \n",
    "            class_value = predictions[index][my_classes[index]]\n",
    "            if threashold is not None and class_value < threashold:\n",
    "                my_classes[index] = -1\n",
    "        print(\"correct: \", (labels == my_classes).sum() ) \n",
    "        print(\"unknown: \", (-1 == my_classes).sum() )\n",
    "        predictions = np.max(predictions, axis = 1) \n",
    "        return my_classes, predictions\n",
    "    \n",
    "\n",
    "#my_classes, distances = predict_with_unknown_class_squere_distance_from_predicted(datasets.MnistDataset(), trained_models, 9108.0)\n",
    "#my_classes, distances = predict_with_unknown_class_squere_distance_from_predicted(datasets.FashionMnistDataset(), trained_models, 9108.0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e2iEECphPu2h"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fNxbVIiIiLVr"
   },
   "outputs": [],
   "source": [
    "predictors = Predictor.__subclasses__()\n",
    "threashoald_list = []\n",
    "for predictor in predictors:\n",
    "    print(predictor.__name__)\n",
    "    instance = predictor()\n",
    "    (_, __), threashoald = instance.predict_test_based_on_train_treshoald(datasets.MnistDataset(), trained_models, 10)\n",
    "    threashoald_list.append(threashoald)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pg3Uok2DPvbR"
   },
   "outputs": [],
   "source": [
    "for index, predictor in enumerate(predictors):\n",
    "    print(predictor.__name__)\n",
    "    instance = predictor()\n",
    "    print(\"Threashold: \", threashoald_list[index])\n",
    "    instance.predict_test(datasets.MnistDataset(), trained_models, threashoald_list[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bgjzTLPWlrlp"
   },
   "outputs": [],
   "source": [
    "fashion_mnist =  datasets.MnistDataset()\n",
    "fashion_mnist.get_test_labels()\n",
    "correct_predict = np.argmax( predictions, axis = 1) == fashion_mnist.get_test_labels()\n",
    "predictions = predictions[correct_predict]\n",
    "predictions = np.max(predictions, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mpcRkQD0lrlr"
   },
   "outputs": [],
   "source": [
    "def plot_bins(predictions, number_of_bins):\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    bins = np.linspace( predictions.min() - 0.01 , predictions.max() + 0.01, num=number_of_bins)\n",
    "\n",
    "    def bins_labels(bins, **kwargs):\n",
    "        bin_w = (max(bins) - min(bins)) / (len(bins) - 1)\n",
    "        plt.xticks(np.arange(min(bins)+bin_w/2, max(bins), bin_w), bins, **kwargs)\n",
    "        plt.xlim(bins[0], bins[-1])\n",
    "\n",
    "    print(bins)\n",
    "    fig, ax = plt.subplots(1,1)\n",
    "    hist = ax.hist(predictions , bins=bins)\n",
    "    labels = [str(count) for count in hist[0]]\n",
    "    #labels.insert(0, 0)\n",
    "    print(labels)\n",
    "    #ax.set_xticklabels(labels)\n",
    "    plt.show()\n",
    "    return bins, labels\n",
    "\n",
    "mnist_bins, mnist_labels = plot_bins(distances, 20)\n",
    "#fashion_mnist_bins, fashion_mnist_labels = plot_bins(fashion_mnist_predictions, 9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3Wq1s_E4lrlu"
   },
   "outputs": [],
   "source": [
    "def print_intervals(bins, labels):\n",
    "    for index, bin in enumerate(bins[:-1]):\n",
    "        print(\"interval: <{:.4f} - {:.4f}, count:{})\".format(bins[index] , bins[index  + 1], labels[index]))\n",
    "#print_intervals(fashion_mnist_bins, fashion_mnist_labels)\n",
    "print_intervals(mnist_bins, mnist_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J0gZj4oGlrl0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_j6e40TwiLWD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "amM5_AAwlrl4"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "rng = np.random.RandomState(10)  # deterministic random data\n",
    "a = np.hstack((rng.normal(size=1000), rng.normal(loc=5, scale=2, size=1000)))\n",
    "_ = plt.hist(a, bins=[-5, 0, 5, 10])  # arguments are passed to np.histogram\n",
    "plt.title(\"Histogram with 'auto' bins\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bCZPlmQO7C_s",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from keras.utils import plot_model\n",
    "# keras.utils.plot_model(models.auto_classifier, show_shapes=True, to_file = 'model_combined.png')\n",
    "import global_functions, constants, vizualizer, experiments\n",
    "logs = global_functions.get_files_in_dir_with_extension(constants.Paths.OUTPUT_DIRECTORY, \".json\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CyipQnhrlrl8"
   },
   "outputs": [],
   "source": [
    "import vizualizer, experiments\n",
    "results = experiments.ExperimentBase.load_experiment_results(constants.ExperimentsPaths.FashionMnist.AUTOENCODER2_CLASSIFIER1_AUTO_L_OFF)\n",
    "vizualizer.Vizualizer.vizualize([result.train_history for result in results], 0.5)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lynGDwpvnOty"
   },
   "outputs": [],
   "source": [
    "model = results[-1].experiment.model_provider()\n",
    "model.classifier .summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "md8JjA3ynXM8"
   },
   "outputs": [],
   "source": [
    "import vizualizer\n",
    "import importlib\n",
    "importlib.reload(vizualizer)\n",
    "vizualizer.Vizualizer.show_autoencoder_images(datasets.FashionMnistDataset(), data.test_y,  predictions, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gJwfndnL9c2Z"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ndeKGRKw7DAO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dSnfKuPd7DAV"
   },
   "outputs": [],
   "source": [
    "def make_batches(to_batch, batch_size = 128):\n",
    "    return [to_batch[i * batch_size:(i + 1) * batch_size] for i in range((len(to_batch) + batch_size - 1) // batch_size )]\n",
    "\n",
    "batch_size = 128\n",
    "to_batch = tf.data.Dataset.from_tensor_slices((train_images, keras.utils.to_categorical(train_labels, 10) ))\n",
    "train_batched = to_batch.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bnzVaDZk7DAc"
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    print(\"Epoch: {}\", epoch)\n",
    "    for step, (images, labels) in enumerate(train_batched):\n",
    "        set_autoencoder_trainable(True)\n",
    "        with tf.GradientTape() as tape:\n",
    "          prediction = autoencoder(images)\n",
    "          loss_autoencoder = autoencoder.loss(images, prediction)\n",
    "          gradients = tape.gradient(loss_autoencoder, autoencoder.trainable_variables)\n",
    "          autoencoder.optimizer.apply_gradients(zip(gradients, autoencoder.trainable_variables))  \n",
    "        set_autoencoder_trainable(False)\n",
    "        with tf.GradientTape() as tape:\n",
    "          predict_class = classifier(images)\n",
    "          loss_classifier = classifier.loss(labels, predict_class)  \n",
    "#           classiefier_trainable = classifier_head.trainable_variables\n",
    "          classiefier_trainable = classifier.trainable_variables\n",
    "          gradients = tape.gradient(loss_classifier, classiefier_trainable)\n",
    "          classifier.optimizer.apply_gradients(zip(gradients  ,classiefier_trainable) ) \n",
    "          if step % 10 == 0:\n",
    "              print(\"Step: {}, loss autoencoder: {}, loss classifier: {}\".format(step, loss_autoencoder.numpy().mean(), loss_classifier.numpy().mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VBxECelEiD8m"
   },
   "outputs": [],
   "source": [
    "for epoch in range(5):\n",
    "  print(\"Classifier\")\n",
    "  historyClassifier = classifier.fit(x = train_images, y = train_labels_one_hot_encoding, batch_size=128, epochs=1, validation_data= (test_images, test_labels_one_hot_encoding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "943GKDIq3HJ8"
   },
   "outputs": [],
   "source": [
    "predictions_auto_encoder, predictions_classifier = auto_classifier.predict(test_images)\n",
    "predictions_classifier = np.argmax(np.round(predictions_classifier),axis=1)\n",
    "correct = np.where(predictions_classifier==test_labels)[0]\n",
    "print( \"Found {} correct labels\".format(len(correct)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v6-io99UHqyl"
   },
   "outputs": [],
   "source": [
    "\n",
    "test_eval = classifier.evaluate(test_images, test_labels_one_hot_encoding, verbose=0)\n",
    "print('Test loss:', test_eval[0])\n",
    "print('Test accuracy:', test_eval[1])\n",
    "predicted_classes = classifier.predict(test_images)\n",
    "predicted_classes = np.argmax(np.round(predicted_classes),axis=1)\n",
    "predicted_classes = predicted_classes.astype('uint8')\n",
    "correct = [predicted_classes[i] == value for i, value in enumerate(test_labels)]\n",
    "print(\"Correct: {}\".format( correct.count(True)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zZQS3niz3YXK"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "for_training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
