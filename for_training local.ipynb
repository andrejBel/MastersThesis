{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 130827,
     "status": "ok",
     "timestamp": 1575454379498,
     "user": {
      "displayName": "Gero Lapan",
      "photoUrl": "",
      "userId": "12575555955150639304"
     },
     "user_tz": -60
    },
    "id": "CAPxLTTaeaaS",
    "outputId": "17c4805f-808c-4f09-bed1-5da44f6aaa9a"
   },
   "outputs": [],
   "source": [
    "import global_functions\n",
    "global_functions.on_start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 130818,
     "status": "ok",
     "timestamp": 1575454379502,
     "user": {
      "displayName": "Gero Lapan",
      "photoUrl": "",
      "userId": "12575555955150639304"
     },
     "user_tz": -60
    },
    "id": "DTKNraAlGLLO",
    "outputId": "aeea20c2-a972-4ada-cfca-cb487fcaaf6b"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "#2.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XD_m4k8AtuU_"
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "import vizualizer, experiments , constants, datasets, models, predictors, training_data, training, reporter\n",
    "importlib.reload(vizualizer)\n",
    "importlib.reload(experiments)\n",
    "importlib.reload(constants)\n",
    "importlib.reload(datasets)\n",
    "importlib.reload(models)\n",
    "importlib.reload(predictors)\n",
    "importlib.reload(training_data)\n",
    "importlib.reload(training)\n",
    "importlib.reload(reporter)\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a8dtVAkVBT8c"
   },
   "outputs": [],
   "source": [
    "#basic_model = models.BasicModelProvider()(datasets.FashionMnistDataset())\n",
    "trained_models.autoencoder.set_autoencoder_trainable(False)\n",
    "existing_model =  models.ExistingModelProvider(lambda: trained_models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dp6xFZW2tUrb"
   },
   "outputs": [],
   "source": [
    "exp = experiments.ExperimentAutoencoder(datasets.MnistDataset, models.BasicModelProvider(),\n",
    "                                                    training_data.BasicTrainingDataGeneratorAutoencoder())\n",
    "result = exp.train(training_data.BasicTrainParametersAutoencoder(100, 128, 20, True, 1.0, 1e-5,\n",
    "                                                                             None,\n",
    "                                                                             False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jf9rE2FQtUrc"
   },
   "outputs": [],
   "source": [
    "\n",
    "exp = experiments.ExperimentClassifier(datasets.FashionMnistDataset, existing_model,\n",
    "                                                   training_data.BasicTrainingDataGeneratorClassifier())\n",
    "result = exp.train(training_data.BasicTrainParametersClassifier(100, 128, 20, True, 1.0, 1e-6, True,\n",
    "                                                                            None,\n",
    "                                                                            False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 134902,
     "status": "ok",
     "timestamp": 1575454383599,
     "user": {
      "displayName": "Gero Lapan",
      "photoUrl": "",
      "userId": "12575555955150639304"
     },
     "user_tz": -60
    },
    "id": "qPY5idqJtUre",
    "outputId": "3d46ef64-6bcf-408f-afe3-a2db06bc5ade"
   },
   "outputs": [],
   "source": [
    "results = experiments.ExperimentBase.load_experiment_results(\n",
    "    constants.ExperimentsPaths.FashionMnist.BasicModelBuilder.AUTOENCODER_TRAINED_CLASSIFIER_AUTO_L_OFF, False)\n",
    "reporter.Reporter.create_classifier_report(results, 'auttrainedoff.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3d5D2n84lT_K",
    "outputId": "7f8ab921-ab8b-49d5-bf6a-0ba4db801fc9"
   },
   "outputs": [],
   "source": [
    "def save_catch(func):\n",
    "    try:\n",
    "        func()\n",
    "    except Exception as error:\n",
    "        print(\"Error: \", error)\n",
    "    \n",
    "for i in range(1):\n",
    "    training.TrainingFashionMnistAveragePoolingWithoutDense.classifier(False)\n",
    "    training.TrainingFashionMnistAveragePoolingWithoutDense.classifier(True)\n",
    "    training.TrainingFashionMnistAveragePoolingWithoutDense.autoencoder_classifier_together(False)\n",
    "    \n",
    "#     save_catch(lambda:training.TrainingFashionMnist.autoencoder())    \n",
    "#     save_catch(lambda:training.TrainingFashionMnist.classifier(True))\n",
    "#     save_catch(lambda:training.TrainingFashionMnist.classifier(False))\n",
    "#     save_catch(lambda:training.TrainingFashionMnist.autoencoder_classifier_together(True))\n",
    "#     save_catch(lambda:training.TrainingFashionMnist.autoencoder_classifier_together(False))\n",
    "#     save_catch(lambda:training.TrainingFashionMnist.autoencoder_trained_then_classifier(True))\n",
    "#     save_catch(lambda:training.TrainingFashionMnist.autoencoder_trained_then_classifier(False))\n",
    "#     save_catch(lambda:training.TrainingFashionMnist.auto_classifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_of_weights[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PhxEaCycY4Dp"
   },
   "outputs": [],
   "source": [
    "# for i, layer in enumerate(trained_models_autoencoder.autoencoder.layers):\n",
    "# new.autoencoder.layers[i].set_weights(layer.get_weights())\n",
    "provideNewWithAutoencoderWeights = experiments.ExistingModelProvider(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1756993,
     "status": "ok",
     "timestamp": 1575064292581,
     "user": {
      "displayName": "Gero Lapan",
      "photoUrl": "",
      "userId": "12575555955150639304"
     },
     "user_tz": -60
    },
    "id": "LM7sCSgDX-46",
    "outputId": "ec64be58-3fdd-4bd5-8f43-538193fae6b3"
   },
   "outputs": [],
   "source": [
    "# newModel = models.BasicModelBuilderWithAveragePoolingWithDenseProvider() (datasets.FashionMnistDataset())\n",
    "# training.TrainingFashionMnist\n",
    "\n",
    "experiment_results_layer_off = []\n",
    "# for rate in [0.01,0.1, 0.25, 0.5, 1]:\n",
    "for repeat in range(1):\n",
    "    for rate in [0.02]:\n",
    "        exp = experiments.ExperimentClassifier(datasets.FashionMnistDataset, provideNewWithAutoencoderWeights,\n",
    "                                               training_data.BasicTrainingDataGeneratorClassifier())\n",
    "        res = exp.train(training_data.BasicTrainParametersClassifier(10, 128, 40, True, rate, 1e-6, False,\n",
    "                                                                     None,\n",
    "                                                                     False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RPXVrTrtuM5S"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "results = experiments.ExperimentBase.load_experiment_results(\n",
    "    constants.ExperimentsPaths.FashionMnist.BasicModelBuilder.CLASSIFIER, False)\n",
    "experiment = results[-1].experiment\n",
    "trained_models_classifier = experiment.model_provider(datasets.FashionMnistDataset())\n",
    "# results = experiments.ExperimentBase.load_experiment_results(constants.ExperimentsPaths.FashionMnist.BasicModelBuilder.CLASSIFIER, True)\n",
    "# experiment = results[-1].experiment\n",
    "# trained_models_autoencoder = experiment.model_provider()\n",
    "\n",
    "#print(len(results))    \n",
    "# vizualizer.Vizualizer.vizualize([result.train_history for result in results], 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_jtr07C7Y4D2"
   },
   "outputs": [],
   "source": [
    "experiments.ExperimentClassifier.predict_test(datasets.FashionMnistDataset(), trained_models_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3Trz-pItxZ3a"
   },
   "outputs": [],
   "source": [
    "fashion_mnist = datasets.FashionMnistDataset()\n",
    "predictions_autoencoder = experiments.ExperimentAutoencoder.predict_test(fashion_mnist ,trained_models)\n",
    "experiments.ExperimentAutoencoder.evaluate_on_test(fashion_mnist, trained_models)\n",
    "vizualizer.Vizualizer.show_random_autoencoder_images(fashion_mnist, fashion_mnist.get_test_images(), predictions_autoencoder, 5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qMfPuqDptUrk"
   },
   "outputs": [],
   "source": [
    "#trained_models = experiment.model_provider()\n",
    "metrics = [ constants.Metrics.VAL_CLASSIFIER_OUT_ACCURACY, constants.Metrics.VAL_AUTOENCODER_OUT_LOSS]\n",
    "params = vizualizer.VizualizeParams(0, 100, 5,False, False, None)\n",
    "#vizualizer.Vizualizer.vizualize([result.train_history for result in results], params)\n",
    "\n",
    "results.sort(key= lambda result: result.train_history.train_parameters.train_data_rate)\n",
    "vizualizer.Vizualizer.vizualize([result.train_history for result in results[:]], params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NTSmy_R-Evtz"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "mnist = datasets.MnistDataset()\n",
    "predictions_classifier = experiments.ExperimentClassifier.predict_train(mnist, trained_models_classifier)\n",
    "predictions_classifier = np.argmax(predictions_classifier, axis = 1)\n",
    "#test_images = mnist.get_test_images()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AKA3nrsZGQXi"
   },
   "outputs": [],
   "source": [
    "incorrect_classifier = [i for i, value in enumerate(fashion_mnist.get_test_labels()) if predictions_classifier[i] != value]\n",
    "correct_classifier = [i for i, value in enumerate(fashion_mnist.get_test_labels()) if predictions_classifier[i] == value]\n",
    "len(incorrect_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LlgTctQhONLn"
   },
   "outputs": [],
   "source": [
    "#test_images[incorrect_classifier]\n",
    "#trained_models_autoencoder.autoencoder.evaluate(test_images[incorrect_classifier],test_images[incorrect_classifier], verbose=2)\n",
    "trained_models_autoencoder.autoencoder.evaluate(test_images[correct_classifier],test_images[correct_classifier], verbose=2)\n",
    "#trained_models_autoencoder.autoencoder.evaluate(test_images,test_images, verbose=2)\n",
    "#incorrect_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kwfo9KMgEvt1"
   },
   "outputs": [],
   "source": [
    "len(correct_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fev4H-4ZEvt3"
   },
   "outputs": [],
   "source": [
    "# #ev = experiments.ExperimentAutoencoder.evaluate_on_train(datasets.MnistDataset() ,trained_models)\n",
    "# fashion_mnist_incorrect = []\n",
    "# for index in incorrect_classifier:\n",
    "#     image = fashion_mnist.get_test_images()[index]\n",
    "#     image = image.reshape(1, 28, 28, 1)\n",
    "#     evaluation = trained_models_autoencoder.autoencoder.evaluate(image, image, verbose = 0)\n",
    "#     fashion_mnist_incorrect.append(evaluation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z0c8GHYWEvt5"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "bins = np.linspace(0,0.6 , 8)\n",
    "\n",
    "plt.hist(fashion_mnist_correct, bins, alpha=0.5, label='Fashion mnist correct')\n",
    "plt.hist(fashion_mnist_incorrect, bins, alpha=0.5, label='Fashion mnist incorrect')\n",
    "plt.xlabel(\"Reconstruction error\")\n",
    "plt.ylabel(\"Number of samples\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n",
    "print(max(fashion_mnist_correct))\n",
    "print(max(fashion_mnist_incorrect))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7QtBQvubVR6j"
   },
   "outputs": [],
   "source": [
    "with open('fashion_mnist_incorrect.txt', 'w') as file:\n",
    "    for index, number in enumerate(fashion_mnist_incorrect):\n",
    "        file.write(str(number))\n",
    "        if index != (len(fashion_mnist_incorrect) - 1):\n",
    "            file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mbUYTLJvVR6m"
   },
   "outputs": [],
   "source": [
    "with open( 'fashion_mnist_incorrect.txt', 'r') as file:\n",
    "    fashion_mnist_incorrect = []\n",
    "    for line in file:\n",
    "        fashion_mnist_incorrect.append(float(line))\n",
    "with open( 'fashion_mnist_correct.txt', 'r') as file:\n",
    "    fashion_mnist_correct = []\n",
    "    for line in file:\n",
    "        fashion_mnist_correct.append(float(line))\n",
    "print(np.mean(fashion_mnist_incorrect))\n",
    "print(np.mean(fashion_mnist_correct))\n",
    "print(np.std(fashion_mnist_incorrect))\n",
    "print(np.std(fashion_mnist_correct))\n",
    "print(len(fashion_mnist_correct))\n",
    "print(len(fashion_mnist_incorrect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3bFJfNAkiLUr"
   },
   "outputs": [],
   "source": [
    "last_layer = trained_models_classifier.classifier.layers[-1]\n",
    "print(last_layer.activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S0Sza95piLU1"
   },
   "outputs": [],
   "source": [
    "trained_models_classifier.make_classifier_without_activation()\n",
    "#trained_models_classifier.make_classifier_with_sigmoid_activation()\n",
    "#spomenut ho, ze bol - histogram sposobil, ze hodnoty boli viac na sebe a pre opacne datasety su podobne, neoddeli mi data. \n",
    "#trained_models_classifier.make_classifier_with_softmax_activation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xbr2cLF-jExd"
   },
   "outputs": [],
   "source": [
    "predictors.Predictor.predict_for_subclasses(datasets.FashionMnistDataset(),  datasets.MnistDataset(), trained_models_classifier, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G7HjbtF1j24b"
   },
   "outputs": [],
   "source": [
    "my_classes, distance = predictors.SquereDistanceFromMean().predict_test_based_on_train_treshoald( datasets.MnistDataset(), trained_models, 10.0)\n",
    "#my_classes, distance = predictors.SquereDistanceFromMean().predict_train( datasets.FashionMnistDataset(), trained_models, None)\n",
    "vizualizer.Vizualizer.plot_bins(distance, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7yma3mlRiLU3"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.percentile(distance, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-pDEp0ihlrln"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F-_VGv-niLVY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e2iEECphPu2h"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fNxbVIiIiLVr"
   },
   "outputs": [],
   "source": [
    "predictors = Predictor.__subclasses__()\n",
    "threashoald_list = []\n",
    "for predictor in predictors:\n",
    "    print(predictor.__name__)\n",
    "    instance = predictor()\n",
    "    (_, __), threashoald = instance.predict_test_based_on_train_treshoald(datasets.MnistDataset(), trained_models, 10)\n",
    "    threashoald_list.append(threashoald)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pg3Uok2DPvbR"
   },
   "outputs": [],
   "source": [
    "for index, predictor in enumerate(predictors):\n",
    "    print(predictor.__name__)\n",
    "    instance = predictor()\n",
    "    print(\"Threashold: \", threashoald_list[index])\n",
    "    instance.predict_test(datasets.MnistDataset(), trained_models, threashoald_list[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bgjzTLPWlrlp"
   },
   "outputs": [],
   "source": [
    "fashion_mnist =  datasets.MnistDataset()\n",
    "fashion_mnist.get_test_labels()\n",
    "correct_predict = np.argmax( predictions, axis = 1) == fashion_mnist.get_test_labels()\n",
    "predictions = predictions[correct_predict]\n",
    "predictions = np.max(predictions, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mpcRkQD0lrlr"
   },
   "outputs": [],
   "source": [
    "def plot_bins(predictions, number_of_bins):\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    bins = np.linspace( predictions.min() - 0.01 , predictions.max() + 0.01, num=number_of_bins)\n",
    "\n",
    "    def bins_labels(bins, **kwargs):\n",
    "        bin_w = (max(bins) - min(bins)) / (len(bins) - 1)\n",
    "        plt.xticks(np.arange(min(bins)+bin_w/2, max(bins), bin_w), bins, **kwargs)\n",
    "        plt.xlim(bins[0], bins[-1])\n",
    "\n",
    "    print(bins)\n",
    "    fig, ax = plt.subplots(1,1)\n",
    "    hist = ax.hist(predictions , bins=bins)\n",
    "    labels = [str(count) for count in hist[0]]\n",
    "    #labels.insert(0, 0)\n",
    "    print(labels)\n",
    "    #ax.set_xticklabels(labels)\n",
    "    plt.show()\n",
    "    return bins, labels\n",
    "\n",
    "mnist_bins, mnist_labels = plot_bins(distances, 20)\n",
    "#fashion_mnist_bins, fashion_mnist_labels = plot_bins(fashion_mnist_predictions, 9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3Wq1s_E4lrlu"
   },
   "outputs": [],
   "source": [
    "def print_intervals(bins, labels):\n",
    "    for index, bin in enumerate(bins[:-1]):\n",
    "        print(\"interval: <{:.4f} - {:.4f}, count:{})\".format(bins[index] , bins[index  + 1], labels[index]))\n",
    "#print_intervals(fashion_mnist_bins, fashion_mnist_labels)\n",
    "print_intervals(mnist_bins, mnist_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J0gZj4oGlrl0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_j6e40TwiLWD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "amM5_AAwlrl4"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "rng = np.random.RandomState(10)  # deterministic random data\n",
    "a = np.hstack((rng.normal(size=1000), rng.normal(loc=5, scale=2, size=1000)))\n",
    "_ = plt.hist(a, bins=[-5, 0, 5, 10])  # arguments are passed to np.histogram\n",
    "plt.title(\"Histogram with 'auto' bins\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bCZPlmQO7C_s",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from keras.utils import plot_model\n",
    "# keras.utils.plot_model(models.auto_classifier, show_shapes=True, to_file = 'model_combined.png')\n",
    "import global_functions, constants, vizualizer, experiments\n",
    "logs = global_functions.get_files_in_dir_with_extension(constants.Paths.OUTPUT_DIRECTORY, \".json\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CyipQnhrlrl8"
   },
   "outputs": [],
   "source": [
    "import vizualizer, experiments\n",
    "results = experiments.ExperimentBase.load_experiment_results(constants.ExperimentsPaths.FashionMnist.AUTOENCODER2_CLASSIFIER1_AUTO_L_OFF)\n",
    "vizualizer.Vizualizer.vizualize([result.train_history for result in results], 0.5)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lynGDwpvnOty"
   },
   "outputs": [],
   "source": [
    "model = results[-1].experiment.model_provider()\n",
    "model.classifier .summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "md8JjA3ynXM8"
   },
   "outputs": [],
   "source": [
    "import vizualizer\n",
    "import importlib\n",
    "importlib.reload(vizualizer)\n",
    "vizualizer.Vizualizer.show_autoencoder_images(datasets.FashionMnistDataset(), data.test_y,  predictions, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gJwfndnL9c2Z"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ndeKGRKw7DAO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dSnfKuPd7DAV"
   },
   "outputs": [],
   "source": [
    "def make_batches(to_batch, batch_size = 128):\n",
    "    return [to_batch[i * batch_size:(i + 1) * batch_size] for i in range((len(to_batch) + batch_size - 1) // batch_size )]\n",
    "\n",
    "batch_size = 128\n",
    "to_batch = tf.data.Dataset.from_tensor_slices((train_images, keras.utils.to_categorical(train_labels, 10) ))\n",
    "train_batched = to_batch.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bnzVaDZk7DAc"
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    print(\"Epoch: {}\", epoch)\n",
    "    for step, (images, labels) in enumerate(train_batched):\n",
    "        set_autoencoder_trainable(True)\n",
    "        with tf.GradientTape() as tape:\n",
    "          prediction = autoencoder(images)\n",
    "          loss_autoencoder = autoencoder.loss(images, prediction)\n",
    "          gradients = tape.gradient(loss_autoencoder, autoencoder.trainable_variables)\n",
    "          autoencoder.optimizer.apply_gradients(zip(gradients, autoencoder.trainable_variables))  \n",
    "        set_autoencoder_trainable(False)\n",
    "        with tf.GradientTape() as tape:\n",
    "          predict_class = classifier(images)\n",
    "          loss_classifier = classifier.loss(labels, predict_class)  \n",
    "#           classiefier_trainable = classifier_head.trainable_variables\n",
    "          classiefier_trainable = classifier.trainable_variables\n",
    "          gradients = tape.gradient(loss_classifier, classiefier_trainable)\n",
    "          classifier.optimizer.apply_gradients(zip(gradients  ,classiefier_trainable) ) \n",
    "          if step % 10 == 0:\n",
    "              print(\"Step: {}, loss autoencoder: {}, loss classifier: {}\".format(step, loss_autoencoder.numpy().mean(), loss_classifier.numpy().mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VBxECelEiD8m"
   },
   "outputs": [],
   "source": [
    "for epoch in range(5):\n",
    "  print(\"Classifier\")\n",
    "  historyClassifier = classifier.fit(x = train_images, y = train_labels_one_hot_encoding, batch_size=128, epochs=1, validation_data= (test_images, test_labels_one_hot_encoding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "943GKDIq3HJ8"
   },
   "outputs": [],
   "source": [
    "predictions_auto_encoder, predictions_classifier = auto_classifier.predict(test_images)\n",
    "predictions_classifier = np.argmax(np.round(predictions_classifier),axis=1)\n",
    "correct = np.where(predictions_classifier==test_labels)[0]\n",
    "print( \"Found {} correct labels\".format(len(correct)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v6-io99UHqyl"
   },
   "outputs": [],
   "source": [
    "\n",
    "test_eval = classifier.evaluate(test_images, test_labels_one_hot_encoding, verbose=0)\n",
    "print('Test loss:', test_eval[0])\n",
    "print('Test accuracy:', test_eval[1])\n",
    "predicted_classes = classifier.predict(test_images)\n",
    "predicted_classes = np.argmax(np.round(predicted_classes),axis=1)\n",
    "predicted_classes = predicted_classes.astype('uint8')\n",
    "correct = [predicted_classes[i] == value for i, value in enumerate(test_labels)]\n",
    "print(\"Correct: {}\".format( correct.count(True)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zZQS3niz3YXK"
   },
   "outputs": [],
   "source": [
    "results = experiments.ExperimentBase.load_experiment_results(\n",
    "    constants.ExperimentsPaths.FashionMnist.BasicModelBuilderWithAveragePoolingWithoutDenseBuilder.AUTOENCODER_TRAINED_CLASSIFIER_AUTO_L_OFF, False)\n",
    "results.sort(key= lambda result: result.train_history. train_parameters. train_data_rate)\n",
    "#results.sort(key= lambda result: result.train_history.train_parameters.train_parameters_classifier.train_data_rate)\n",
    "reporter.Reporter.create_classifier_report(results, 'vysledky_10_12_2019.xlsx', \"4. Autoenkóder natrénovaný a dotrénovanie klasifikátora - vrstvy enkódera nie sú trénovateľné\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainParameters(batch_size=128, epochs=1, min_delta=1e-07, patience=None, train_data_rate=0.01, validate=True)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "for_training local.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
