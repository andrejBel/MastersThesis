{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Autoencoderstart.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"cells":[{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1572700993768,"user_tz":-60,"elapsed":56875,"user":{"displayName":"Gero Lapan","photoUrl":"","userId":"12575555955150639304"}},"id":"XNigl-_y7C_F","outputId":"e3fa9f42-f00c-4a8f-af0c-f9354c6376b7","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["IS_LINUX = False\n","from sys import platform\n","if platform == \"linux\" or platform == \"linux2\":\n","  IS_LINUX = True\n","if IS_LINUX:\n","    !pip install tensorflow-gpu\n","    !pip install jsonpickle"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting tensorflow-gpu\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/44/47f0722aea081697143fbcf5d2aa60d1aee4aaacb5869aee2b568974777b/tensorflow_gpu-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (380.8MB)\n","\u001b[K     |████████████████████████████████| 380.8MB 45kB/s \n","\u001b[?25hRequirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.2.2)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n","Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.17.3)\n","Collecting tensorboard<2.1.0,>=2.0.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d3/9e/a48cd34dd7b672ffc227b566f7d16d63c62c58b542d54efa45848c395dd4/tensorboard-2.0.1-py3-none-any.whl (3.8MB)\n","\u001b[K     |████████████████████████████████| 3.8MB 37.6MB/s \n","\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.33.6)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.1.0)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.8.1)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12.0)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.1.7)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.11.2)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.8.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.15.0)\n","Collecting tensorflow-estimator<2.1.0,>=2.0.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/08/8b927337b7019c374719145d1dceba21a8bb909b93b1ad6f8fb7d22c1ca1/tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449kB)\n","\u001b[K     |████████████████████████████████| 450kB 41.8MB/s \n","\u001b[?25hRequirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.0.8)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.10.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (3.1.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (41.4.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (0.4.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (0.16.0)\n","Collecting google-auth<2,>=1.6.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c5/9b/ed0516cc1f7609fb0217e3057ff4f0f9f3e3ce79a369c6af4a6c5ca25664/google_auth-1.6.3-py2.py3-none-any.whl (73kB)\n","\u001b[K     |████████████████████████████████| 81kB 10.4MB/s \n","\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu) (2.8.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (1.2.0)\n","Requirement already satisfied: cachetools>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (3.1.1)\n","Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (4.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (0.2.7)\n","Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (2.21.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (3.1.0)\n","Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (0.4.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (2019.9.11)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (3.0.4)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (2.8)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (1.24.3)\n","\u001b[31mERROR: tensorflow 1.15.0 has requirement tensorboard<1.16.0,>=1.15.0, but you'll have tensorboard 2.0.1 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow 1.15.0 has requirement tensorflow-estimator==1.15.1, but you'll have tensorflow-estimator 2.0.1 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorboard 2.0.1 has requirement grpcio>=1.24.3, but you'll have grpcio 1.15.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: google-colab 1.0.0 has requirement google-auth~=1.4.0, but you'll have google-auth 1.6.3 which is incompatible.\u001b[0m\n","Installing collected packages: google-auth, tensorboard, tensorflow-estimator, tensorflow-gpu\n","  Found existing installation: google-auth 1.4.2\n","    Uninstalling google-auth-1.4.2:\n","      Successfully uninstalled google-auth-1.4.2\n","  Found existing installation: tensorboard 1.15.0\n","    Uninstalling tensorboard-1.15.0:\n","      Successfully uninstalled tensorboard-1.15.0\n","  Found existing installation: tensorflow-estimator 1.15.1\n","    Uninstalling tensorflow-estimator-1.15.1:\n","      Successfully uninstalled tensorflow-estimator-1.15.1\n","Successfully installed google-auth-1.6.3 tensorboard-2.0.1 tensorflow-estimator-2.0.1 tensorflow-gpu-2.0.0\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["google"]}}},"metadata":{"tags":[]}},{"output_type":"stream","text":["Collecting jsonpickle\n","  Downloading https://files.pythonhosted.org/packages/07/07/c157520a3ebd166c8c24c6ae0ecae7c3968eb4653ff0e5af369bb82f004d/jsonpickle-1.2-py2.py3-none-any.whl\n","Installing collected packages: jsonpickle\n","Successfully installed jsonpickle-1.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1572701219009,"user_tz":-60,"elapsed":282111,"user":{"displayName":"Gero Lapan","photoUrl":"","userId":"12575555955150639304"}},"id":"DswxGqi-sw4E","outputId":"31d039da-98ec-4870-c649-fab8155665c9","colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["if IS_LINUX:\n","    from google.colab import drive\n","    drive.mount('/content/drive', force_remount=True)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1572701223654,"user_tz":-60,"elapsed":286753,"user":{"displayName":"Gero Lapan","photoUrl":"","userId":"12575555955150639304"}},"id":"iUj0zEbRs1ts","outputId":"ca17e9aa-c7a5-4c62-8ea3-0d758cad033d","colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["if IS_LINUX:\n","    %cd /content/drive/My\\ Drive/MastersThesis\n","    !ls\n","    !pwd\n","    import sys\n","    sys.path.append('./')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/MastersThesis\n"," Autoencoderstart.ipynb   model_combined.png\n"," callbacks.py\t\t  models.py\n"," config.py\t\t  named_constants.py\n"," constants.py\t\t  output_dir\n"," datasets.py\t\t  __pycache__\n"," experiments.py\t\t  README.md\n"," for_fun.py\t\t  training_data.py\n"," for_training.ipynb\t  vizualizer.py\n"," global_functions.py\t 'Vysledky Fashion mnist 22.10.2019 basic model.xlsx'\n","/content/drive/My Drive/MastersThesis\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qVQkNERcTFvo","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"6864cdaa-efbd-4864-ee27-94718b15ea53","executionInfo":{"status":"ok","timestamp":1572701437036,"user_tz":-60,"elapsed":1576,"user":{"displayName":"Gero Lapan","photoUrl":"","userId":"12575555955150639304"}}},"source":["try:\n","    import google.colab\n","    IS_COLAB = True\n","except:\n","    IS_COLAB = False\n","IS_COLAB"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"CAPxLTTaeaaS","colab":{}},"source":["import global_functions\n","global_functions.on_start()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"DTKNraAlGLLO","colab":{}},"source":["import tensorflow as tf\n","print(tf.__version__)\n","#2.0.0"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"XD_m4k8AtuU_","colab":{}},"source":["import experiments, datasets, training_data\n","import models\n","import constants\n","import vizualizer\n","\n","from global_functions import on_start\n","on_start()\n","\n","for repeat in range(1):\n","    for rate in [0.1, 0.25, 0.5, 1]:\n","        exp = experiments.ExperimentAutoencoder(datasets.MnistDataset, models.BasicModelProvider(),\n","                                                training_data.BasicTrainingDataGeneratorAutoencoder()\n","                                                )\n","        exp.train(training_data.BasicTrainParametersAutoencoder(100, 128, 20, True, rate, 1e-5,\n","                                                                constants.ExperimentsPaths.Mnist.AUTOENCODER,\n","                                                                True))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lMi2u67QuP3L","colab_type":"code","colab":{}},"source":["import experiments, datasets, training_data\n","import models\n","import constants\n","import vizualizer\n","\n","from global_functions import on_start\n","on_start()\n","# 2\n","for repeat in range(1):\n","    for rate in [0.1, 0.25, 0.5, 1]:\n","        data_provider = training_data.BasicTrainingDataGeneratorClassifier\n","        exp = experiments.ExperimentClassifier(datasets.MnistDataset, models.BasicModelProvider(),\n","                                               training_data.BasicTrainingDataGeneratorClassifier())\n","        exp.train(training_data.BasicTrainParametersClassifier(100, 128, 20, True, rate, 1e-6, True,\n","                                                               constants.ExperimentsPaths.Mnist.CLASSIFIER, True)\n","                  )"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"uODtmIAeXG87","colab":{}},"source":["import vizualizer, experiments, constants, datasets\n","\n","results = experiments.ExperimentBase.load_experiment_results(constants.ExperimentsPaths.Mnist.CLASSIFIER, False)\n","vizualizer.Vizualizer.vizualize([result.train_history for result in results], 0.5)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"RPXVrTrtuM5S","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"dSnfKuPd7DAV","colab":{}},"source":["def make_batches(to_batch, batch_size = 128):\n","    return [to_batch[i * batch_size:(i + 1) * batch_size] for i in range((len(to_batch) + batch_size - 1) // batch_size )]\n","\n","batch_size = 128\n","to_batch = tf.data.Dataset.from_tensor_slices((train_images, keras.utils.to_categorical(train_labels, 10) ))\n","train_batched = to_batch.batch(batch_size)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"bnzVaDZk7DAc","colab":{}},"source":["epochs = 10\n","for epoch in range(epochs):\n","    print(\"Epoch: {}\", epoch)\n","    for step, (images, labels) in enumerate(train_batched):\n","        set_autoencoder_trainable(True)\n","        with tf.GradientTape() as tape:\n","          prediction = autoencoder(images)\n","          loss_autoencoder = autoencoder.loss(images, prediction)\n","          gradients = tape.gradient(loss_autoencoder, autoencoder.trainable_variables)\n","          autoencoder.optimizer.apply_gradients(zip(gradients, autoencoder.trainable_variables))  \n","        set_autoencoder_trainable(False)\n","        with tf.GradientTape() as tape:\n","          predict_class = classifier(images)\n","          loss_classifier = classifier.loss(labels, predict_class)  \n","#           classiefier_trainable = classifier_head.trainable_variables\n","          classiefier_trainable = classifier.trainable_variables\n","          gradients = tape.gradient(loss_classifier, classiefier_trainable)\n","          classifier.optimizer.apply_gradients(zip(gradients  ,classiefier_trainable) ) \n","          if step % 10 == 0:\n","              print(\"Step: {}, loss autoencoder: {}, loss classifier: {}\".format(step, loss_autoencoder.numpy().mean(), loss_classifier.numpy().mean()))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"VBxECelEiD8m","colab":{}},"source":["for epoch in range(5):\n","  print(\"Classifier\")\n","  historyClassifier = classifier.fit(x = train_images, y = train_labels_one_hot_encoding, batch_size=128, epochs=1, validation_data= (test_images, test_labels_one_hot_encoding))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"943GKDIq3HJ8","colab":{}},"source":["predictions_auto_encoder, predictions_classifier = auto_classifier.predict(test_images)\n","predictions_classifier = np.argmax(np.round(predictions_classifier),axis=1)\n","correct = np.where(predictions_classifier==test_labels)[0]\n","print( \"Found {} correct labels\".format(len(correct)))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"v6-io99UHqyl","colab":{}},"source":["\n","test_eval = classifier.evaluate(test_images, test_labels_one_hot_encoding, verbose=0)\n","print('Test loss:', test_eval[0])\n","print('Test accuracy:', test_eval[1])\n","predicted_classes = classifier.predict(test_images)\n","predicted_classes = np.argmax(np.round(predicted_classes),axis=1)\n","predicted_classes = predicted_classes.astype('uint8')\n","correct = [predicted_classes[i] == value for i, value in enumerate(test_labels)]\n","print(\"Correct: {}\".format( correct.count(True)))\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"zZQS3niz3YXK","colab":{}},"source":["predictions = autoencoder.predict(test_images)\n","# rand_start = np.random.randint(0, len(predictions) - 10)\n","# for i in range(rand_start, rand_start + 10):\n","#   plotImage(predictions[i].reshape(28, 28), \"Predictions\")\n","#   plotImage(test_images[i].reshape(28, 28), \"Original\")\n","\n","\n","num_images = 5\n","#np.random.seed(42)\n","random_test_images = np.random.randint(test_images.shape[0], size=num_images)\n","\n","decoded_imgs = predictions\n","\n","\n","plt.figure(figsize=(28, 16))\n","\n","for i, image_idx in enumerate(random_test_images):\n","    # plot original image\n","    ax = plt.subplot(2, num_images, i + 1)\n","    plt.title(\"Original\")\n","    plt.imshow(process_for_plotting(test_images[image_idx]))\n","    plt.gray()\n","    ax.get_xaxis().set_visible(False)\n","    ax.get_yaxis().set_visible(False)\n","    \n","    # # plot encoded image\n","    # ax = plt.subplot(3, num_images, num_images + i + 1)\n","    # plt.imshow(encoded_imgs[image_idx].reshape(8, 4))\n","    # plt.gray()\n","    # ax.get_xaxis().set_visible(False)\n","    # ax.get_yaxis().set_visible(False)\n","\n","    # plot reconstructed image\n","    ax = plt.subplot(2, num_images, num_images + i + 1)\n","    plt.imshow(process_for_plotting(decoded_imgs[image_idx])) #reshape(28, 28)\n","    plt.title(\"Predicted\")\n","    plt.gray()\n","    ax.get_xaxis().set_visible(False)\n","    ax.get_yaxis().set_visible(False)\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"H2f_wRVkcEsj","colab":{}},"source":["\n","from experiments import *\n","import jsonpickle\n","exp = ExperimentAutoencoder(DatasetProviderClass(FashionMnistDataset), basic_model_provider, generate_data_for_trainig)\n","exp.train(BasicTrainParameters(1, 128, True, 'mylog.json', True) )\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"BGniThsUcEsl","colab":{}},"source":["from experiments import *\n","exp = ExperimentAutoencoder(DatasetProviderClass(FashionMnistDataset), basic_model_provider, generate_data_for_trainig)\n","# exp.train(BasicTrainParameters(1, 128, True, 'mylog.json', True) )\n","# exp.train(BasicTrainParameters(2, 128, True, 'mylog.json', True) )\n","train_result = exp.train(BasicTrainParameters(3, 128, True, 'mylog.json', True) )\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"mLk13a9icEsm","colab":{}},"source":["exp_local = train_result[1]\n","exp_local"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"OYcjaDOccEso","colab":{}},"source":["import experiments\n","import datasets\n","import importlib\n","importlib.reload(experiments)\n","for rate in [1]:\n","    exp = experiments.ExperimentAutoencoder(experiments.DatasetProviderClass(datasets.FashionMnistDataset), experiments.BasicModelProvider(), experiments.generate_data_for_trainig)\n","    exp.train(experiments.BasicTrainParametersOneModel(100, 128, 10, True, rate, 0.001, 'mylog.json', True))\n","    #exp.train(experiments.BasicTrainParametersOneModel(100, 128, True, rate, 'mylog.json', True))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"xO86V741cEsq","colab":{}},"source":["import vizualizer\n","import experiments\n","import importlib\n","importlib.reload(vizualizer)\n","results = experiments.ExperimentBase.load_experiment_results('classifier.json')\n","vizualizer.Vizualizer.vizualize([result.train_history for result in results], 0.5)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"OGbyhSsScEsx","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"bOba6SPrcEsz","colab":{}},"source":["\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"wkbq1P3ecEs1","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"nCAydIuUcEs3","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"dZMOHTW2cEs6","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"yb7HOYsYcEs_","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}