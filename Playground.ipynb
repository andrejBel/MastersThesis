{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XNigl-_y7C_F"
   },
   "outputs": [],
   "source": [
    "IS_COLAB = False\n",
    "try:\n",
    "    import google.colab\n",
    "    IS_COLAB = True\n",
    "except:\n",
    "    pass\n",
    "if IS_COLAB:\n",
    "    !pip install tensorflow-gpu\n",
    "    !pip install jsonpickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DswxGqi-sw4E"
   },
   "outputs": [],
   "source": [
    "if IS_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iUj0zEbRs1ts"
   },
   "outputs": [],
   "source": [
    "if IS_COLAB:\n",
    "    %cd /content/drive/My\\ Drive/MastersThesis\n",
    "    !ls\n",
    "    !pwd\n",
    "    import sys\n",
    "    sys.path.append('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vO8sbi7vCUCO"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "if tf.test.is_gpu_available():\n",
    "    print(\"GPU OK\")\n",
    "else:\n",
    "    print(\"GPU NOT FOUND\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1dMRFpb4C29c"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "    raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CAPxLTTaeaaS"
   },
   "outputs": [],
   "source": [
    "import global_functions\n",
    "global_functions.on_start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lMi2u67QuP3L"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jejj6VRUA4Cd"
   },
   "outputs": [],
   "source": [
    "import training\n",
    "training.TrainingFashionMnist.classifier_layers_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uODtmIAeXG87"
   },
   "outputs": [],
   "source": [
    "import vizualizer, experiments, constants, datasets\n",
    "\n",
    "results = experiments.ExperimentBase.load_experiment_results(constants.ExperimentsPaths.Mnist.CLASSIFIER, False)\n",
    "vizualizer.Vizualizer.vizualize([result.train_history for result in results], 0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RPXVrTrtuM5S"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dSnfKuPd7DAV"
   },
   "outputs": [],
   "source": [
    "def make_batches(to_batch, batch_size = 128):\n",
    "    return [to_batch[i * batch_size:(i + 1) * batch_size] for i in range((len(to_batch) + batch_size - 1) // batch_size )]\n",
    "\n",
    "batch_size = 128\n",
    "to_batch = tf.data.Dataset.from_tensor_slices((train_images, keras.utils.to_categorical(train_labels, 10) ))\n",
    "train_batched = to_batch.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bnzVaDZk7DAc"
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    print(\"Epoch: {}\", epoch)\n",
    "    for step, (images, labels) in enumerate(train_batched):\n",
    "        set_autoencoder_trainable(True)\n",
    "        with tf.GradientTape() as tape:\n",
    "          prediction = autoencoder(images)\n",
    "          loss_autoencoder = autoencoder.loss(images, prediction)\n",
    "          gradients = tape.gradient(loss_autoencoder, autoencoder.trainable_variables)\n",
    "          autoencoder.optimizer.apply_gradients(zip(gradients, autoencoder.trainable_variables))  \n",
    "        set_autoencoder_trainable(False)\n",
    "        with tf.GradientTape() as tape:\n",
    "          predict_class = classifier(images)\n",
    "          loss_classifier = classifier.loss(labels, predict_class)  \n",
    "#           classiefier_trainable = classifier_head.trainable_variables\n",
    "          classiefier_trainable = classifier.trainable_variables\n",
    "          gradients = tape.gradient(loss_classifier, classiefier_trainable)\n",
    "          classifier.optimizer.apply_gradients(zip(gradients  ,classiefier_trainable) ) \n",
    "          if step % 10 == 0:\n",
    "              print(\"Step: {}, loss autoencoder: {}, loss classifier: {}\".format(step, loss_autoencoder.numpy().mean(), loss_classifier.numpy().mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VBxECelEiD8m"
   },
   "outputs": [],
   "source": [
    "for epoch in range(5):\n",
    "  print(\"Classifier\")\n",
    "  historyClassifier = classifier.fit(x = train_images, y = train_labels_one_hot_encoding, batch_size=128, epochs=1, validation_data= (test_images, test_labels_one_hot_encoding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "943GKDIq3HJ8"
   },
   "outputs": [],
   "source": [
    "predictions_auto_encoder, predictions_classifier = auto_classifier.predict(test_images)\n",
    "predictions_classifier = np.argmax(np.round(predictions_classifier),axis=1)\n",
    "correct = np.where(predictions_classifier==test_labels)[0]\n",
    "print( \"Found {} correct labels\".format(len(correct)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v6-io99UHqyl"
   },
   "outputs": [],
   "source": [
    "\n",
    "test_eval = classifier.evaluate(test_images, test_labels_one_hot_encoding, verbose=0)\n",
    "print('Test loss:', test_eval[0])\n",
    "print('Test accuracy:', test_eval[1])\n",
    "predicted_classes = classifier.predict(test_images)\n",
    "predicted_classes = np.argmax(np.round(predicted_classes),axis=1)\n",
    "predicted_classes = predicted_classes.astype('uint8')\n",
    "correct = [predicted_classes[i] == value for i, value in enumerate(test_labels)]\n",
    "print(\"Correct: {}\".format( correct.count(True)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zZQS3niz3YXK"
   },
   "outputs": [],
   "source": [
    "predictions = autoencoder.predict(test_images)\n",
    "# rand_start = np.random.randint(0, len(predictions) - 10)\n",
    "# for i in range(rand_start, rand_start + 10):\n",
    "#   plotImage(predictions[i].reshape(28, 28), \"Predictions\")\n",
    "#   plotImage(test_images[i].reshape(28, 28), \"Original\")\n",
    "\n",
    "\n",
    "num_images = 5\n",
    "#np.random.seed(42)\n",
    "random_test_images = np.random.randint(test_images.shape[0], size=num_images)\n",
    "\n",
    "decoded_imgs = predictions\n",
    "\n",
    "\n",
    "plt.figure(figsize=(28, 16))\n",
    "\n",
    "for i, image_idx in enumerate(random_test_images):\n",
    "    # plot original image\n",
    "    ax = plt.subplot(2, num_images, i + 1)\n",
    "    plt.title(\"Original\")\n",
    "    plt.imshow(process_for_plotting(test_images[image_idx]))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "    # # plot encoded image\n",
    "    # ax = plt.subplot(3, num_images, num_images + i + 1)\n",
    "    # plt.imshow(encoded_imgs[image_idx].reshape(8, 4))\n",
    "    # plt.gray()\n",
    "    # ax.get_xaxis().set_visible(False)\n",
    "    # ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # plot reconstructed image\n",
    "    ax = plt.subplot(2, num_images, num_images + i + 1)\n",
    "    plt.imshow(process_for_plotting(decoded_imgs[image_idx])) #reshape(28, 28)\n",
    "    plt.title(\"Predicted\")\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H2f_wRVkcEsj"
   },
   "outputs": [],
   "source": [
    "\n",
    "from experiments import *\n",
    "import jsonpickle\n",
    "exp = ExperimentAutoencoder(DatasetProviderClass(FashionMnistDataset), basic_model_provider, generate_data_for_trainig)\n",
    "exp.train(BasicTrainParameters(1, 128, True, 'mylog.json', True) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BGniThsUcEsl"
   },
   "outputs": [],
   "source": [
    "from experiments import *\n",
    "exp = ExperimentAutoencoder(DatasetProviderClass(FashionMnistDataset), basic_model_provider, generate_data_for_trainig)\n",
    "# exp.train(BasicTrainParameters(1, 128, True, 'mylog.json', True) )\n",
    "# exp.train(BasicTrainParameters(2, 128, True, 'mylog.json', True) )\n",
    "train_result = exp.train(BasicTrainParameters(3, 128, True, 'mylog.json', True) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mLk13a9icEsm"
   },
   "outputs": [],
   "source": [
    "exp_local = train_result[1]\n",
    "exp_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OYcjaDOccEso"
   },
   "outputs": [],
   "source": [
    "import experiments\n",
    "import datasets\n",
    "import importlib\n",
    "importlib.reload(experiments)\n",
    "for rate in [1]:\n",
    "    exp = experiments.ExperimentAutoencoder(experiments.DatasetProviderClass(datasets.FashionMnistDataset), experiments.BasicModelProvider(), experiments.generate_data_for_trainig)\n",
    "    exp.train(experiments.BasicTrainParametersOneModel(100, 128, 10, True, rate, 0.001, 'mylog.json', True))\n",
    "    #exp.train(experiments.BasicTrainParametersOneModel(100, 128, True, rate, 'mylog.json', True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xO86V741cEsq"
   },
   "outputs": [],
   "source": [
    "import vizualizer\n",
    "import experiments\n",
    "import importlib\n",
    "importlib.reload(vizualizer)\n",
    "results = experiments.ExperimentBase.load_experiment_results('classifier.json')\n",
    "vizualizer.Vizualizer.vizualize([result.train_history for result in results], 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OGbyhSsScEsx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bOba6SPrcEsz"
   },
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "from openpyxl import Workbook\n",
    "wb = openpyxl.load_workbook('sample.xlsx')\n",
    "\n",
    "# grab the active worksheet\n",
    "ws = wb.active\n",
    "\n",
    "# Rows can also be appended\n",
    "ws.append([1, 2, 3])\n",
    "\n",
    "# # Python types will automatically be converted\n",
    "# import datetime\n",
    "ws['A2'] = '12'\n",
    "\n",
    "# Save the file\n",
    "wb.save(\"sample.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wkbq1P3ecEs1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nCAydIuUcEs3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dZMOHTW2cEs6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yb7HOYsYcEs_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Autoencoderstart.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
